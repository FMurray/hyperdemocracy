{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FMurray/hyperdemocracy/blob/main/hyper_democracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KkXxD28y6u2w"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are on a google colab, uncomment the lines below to fetch the requirements file and the hyperdemocracy.py module\n",
    "# and pip install the requirements\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/FMurray/hyperdemocracy/main/requirements.txt\n",
    "#!wget https://raw.githubusercontent.com/FMurray/hyperdemocracy/main/hyperdemocracy.py\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rich\n",
    "import time\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a Provider\n",
    "\n",
    "We have options for HuggingFace and OpenAI model providers in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROVIDER = \"HF\"\n",
    "PROVIDER = \"OPENAI\"\n",
    "\n",
    "assert PROVIDER in [\"HF\", \"OPENAI\"]\n",
    "\n",
    "CONFIGS = {\n",
    "    \"HF\": {\n",
    "        \"embd\": \"sentence-transformers/all-mpnet-base-v2\",\n",
    "        \"llm\": \"google/flan-t5-base\",\n",
    "        #\"llm\": \"google/flan-t5-large\",\n",
    "        #\"llm\": \"google/flan-ul2\",\n",
    "    },\n",
    "    \"OPENAI\": {\n",
    "        \"embd\": \"text-embedding-ada-002\",\n",
    "        \"llm\": \"gpt-3.5-turbo-16k\",\n",
    "    },\n",
    "}\n",
    "\n",
    "CONFIG = CONFIGS[PROVIDER]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on Formatted Output\n",
    "\n",
    "Note that we patch the builtin Python `print` function with `rich.print` in the cell below. If you prefer a more traditional print output you can comment out the import below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on Cost (OpenAI Only, HF is Free)\n",
    "\n",
    "Running this notebook with your OpenAI key in an environment variable will charge a small amount of money to your OpenAI account. The total cost of running this notebook multiple times should be less than $5 but that can change if the datasource is changed. Each cell that makes a request to an OpenAI endpoint that costs money will have the following comment in it, \n",
    "\n",
    "```\n",
    "## THIS CELL SPENDS MONEY ##\n",
    "```\n",
    "\n",
    "Up to date pricing information on OpenAI models can be found here https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DOLLARS_PER_1K_TOKENS = 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqdS7Elhfpl"
   },
   "source": [
    "# Setup Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use local secrets, add a file called .env to this directory and uncomment the lines below\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtSzpF4Ehii5"
   },
   "outputs": [],
   "source": [
    "# if you are using google colab, uncomment the lines below to manually enter your OpenAI key.\n",
    "\n",
    "#import getpass\n",
    "#os.environ['OPENAI_API_KEY'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are using google colab, uncomment the lines below to manually enter your HuggingFace token.\n",
    "\n",
    "#import getpass\n",
    "#os.environ['HUGGINGFACEHUB_API_TOKEN'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for development\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vSe6gY8_gazO"
   },
   "source": [
    "# Load Assembleco Records\n",
    "\n",
    "We are going to use a small subset of records provided by https://assembled.app/.\n",
    "\n",
    "For the purposes of this workshop, we have created a [huggingface dataset](https://huggingface.co/datasets/assembleco/hyperdemocracy)  which we can load using the `load_dataset` function. This is all handled for you in the `load_assembleco_records` function. See more info here [datasets](https://huggingface.co/docs/datasets/index) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperdemocracy import load_assembleco_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_assembleco_records(process=True, strip_html=True, remove_empty_body=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5r6oJ7MmQM5"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4eSYiO5Ii9X"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-HUxJ4XAFOaZ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sponsor Graph Sidequest\n",
    "\n",
    "We will be focusing on the text content of the legislation in this workshop, but if you would like to explore building a graph from the sponsor / co-sponsor / legislation network check out the [sponsor_graph notebook](https://github.com/FMurray/hyperdemocracy/blob/main/sidequests/sponsor_graph.ipynb) to get started."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5GM8DqH7Ojeu"
   },
   "source": [
    "# From Pandas Dataframe to LangChain Documents\n",
    "\n",
    "A langchain document is a simple class with two attributes, \n",
    "* page_content (a string)\n",
    "* metadata (a dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DH58_PTsRJyD"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we take each row from our legislation DataFrame and create a LangChain Document. We use the `body` column for the `page_content` attribute and populate the `metadata` attribute with data from some of the other columns. Note that the `source` key in the `metadata` dictionary is associated with a congress.gov url. The `source` key can hold an arbitrary string and will become important when we look into question answering systems that return information about the sources used to answer a question. We also restrict ourselves to `str`, `int`, and `float` types in the other values of our `metadata` dictionary. This is to make it easy to use them as filters when querying our vectorstore. If that doesn't make sense, dont worry! It will by the end of the workshop.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to embed all the assembled records, you can filter using a search query here:\n",
    "\n",
    "from hyperdemocracy import filter_aco_df\n",
    "query = \"energy\"\n",
    "df = filter_aco_df(df, query)\n",
    "\n",
    "# if that doesn't work for your needs, you can just take a random sample of some number\n",
    "#df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLHx06mHepKQ"
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for irow, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=row['body'],\n",
    "        metadata={\n",
    "            # Note: chroma can only filter on float, str, or int\n",
    "            # https://docs.trychroma.com/usage-guide#using-where-filters\n",
    "            'key': row['key'],\n",
    "            'congress_num': row['congress_num'],\n",
    "            'legis_class': row['legis_class'],\n",
    "            'legis_num': row['legis_num'],\n",
    "            'name': row['name'],\n",
    "            'summary': row['summary'],\n",
    "            'sponsor': row['sponsors'][0][0],\n",
    "            'source': row['congress_gov_url'],\n",
    "        },\n",
    "    )\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-fFRGsTUDGX"
   },
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "* examine the Document content\n",
    "* visit the congress.gov URL and view the document in various formats\n",
    "* examine the body text below\n",
    "* read the summary of the document and attempt to connect it with the long form text of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fceFBIiDRcZk"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siRiWjCyj63F"
   },
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the token counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBZermt7U07_"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_openai_tokens_in_docs(docs, model_name=CONFIG[\"embd\"]):\n",
    "    num_tokens = 0\n",
    "    enc = tiktoken.encoding_for_model(model_name)\n",
    "    for doc in docs:\n",
    "        num_tokens += len(enc.encode(doc.page_content))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hf_tokens_in_docs(docs, model_name=CONFIG[\"embd\"]):\n",
    "    num_tokens = 0\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"embd\"])\n",
    "    for doc in docs:\n",
    "        num_tokens += len(tokenizer(docs[0].page_content)['input_ids'])\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate cost\n",
    "if PROVIDER == \"OPENAI\":\n",
    "    num_tokens = count_openai_tokens_in_docs(docs)\n",
    "    cost = EMBED_DOLLARS_PER_1K_TOKENS * num_tokens / 1000\n",
    "    print('Num Docs: ', len(docs))\n",
    "    print('Num Tokens: ', num_tokens)\n",
    "    print('Total Cost (USD): ', '$'+str(cost))\n",
    "elif PROVIDER == \"HF\":\n",
    "    num_tokens = count_hf_tokens_in_docs(docs)\n",
    "    cost = 0\n",
    "    print('Num Docs: ', len(docs))\n",
    "    print('Num Tokens: ', num_tokens)\n",
    "    print('Total Cost (USD): ', '$'+str(cost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "* Contemplate why the answers are slightly different between the \"QA\" result and the \"QA with sources\" result.\n",
    "* Visit the source links and check if the linked legislation is relevant to the question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4ry8zdrlCEqi"
   },
   "source": [
    "# Document QA - Step by Step\n",
    "\n",
    "Our goal is to setup a question answering (QA) system that can repond to natural language questions about legislation using source material that we provide. In the following sections we will unpack all of components and go over them in detail."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KCdDA0eOXJ_1"
   },
   "source": [
    "# Part 1 - Langchain Text Splitters\n",
    "\n",
    "> When you want to deal with long pieces of text, it is necessary to split up that text into chunks. As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\n",
    "\n",
    "> At a high level, text splitters work as following:\n",
    "\n",
    ">    1. Split the text up into small, semantically meaningful chunks (often sentences).\n",
    ">    2. Start combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).\n",
    ">    3. Once you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).\n",
    "\n",
    "> That means there are two different axes along which you can customize your text splitter:\n",
    "\n",
    ">    1. How the text is split\n",
    ">    2. How the chunk size is measured\n",
    "\n",
    "-- https://python.langchain.com/docs/modules/data_connection/document_transformers/#text-splitters\n",
    "\n",
    "Here are some useful options for splitting legislative text, \n",
    "\n",
    "* [character text splitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter)\n",
    "  * How the text is split: by single character\n",
    "  * How the chunk size is measured: by number of characters\n",
    "* [recursive text splitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)\n",
    "  * How the text is split: by list of characters\n",
    "  * How the chunk size is measured: by number of characters\n",
    "* [split by token](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/split_by_token)\n",
    "  * How the text is split: by character passed in\n",
    "  * How the chunk size is measured: by tiktoken tokenizer\n",
    "\n",
    "If you are not familiar with the concept of a token, this article may help, \n",
    "* https://simonwillison.net/2023/Jun/8/gpt-tokenizers/\n",
    "\n",
    "## Side Quest\n",
    "* check out the [text splitting notebook](https://github.com/FMurray/hyperdemocracy/blob/main/sidequests/text_splitting.ipynb) side quest to see more details on text splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w6e8Bcia6gp"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Make a TextSplitter Choice here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCi59g8rFAMi"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da7F2FUuFR8q"
   },
   "outputs": [],
   "source": [
    "print(\"Number of original docs: \", len(docs))\n",
    "print(\"Number of split docs: \", len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_docs[50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7BVOa0TebHtY"
   },
   "source": [
    "# Part 2 - Embed and Index Doc Chunks\n",
    "\n",
    "Now we will embed and index the document chunks from the previous section. \n",
    "We have many choices when it comes to text embedding models and vector indexes. \n",
    "For this tutorial we will choose, \n",
    "\n",
    "* text embedding model: `text_embedding_ada_002`\n",
    "* vector index:\n",
    "  * https://www.trychroma.com\n",
    "  * https://docs.trychroma.com/usage-guide#changing-the-distance-function\n",
    "  * https://github.com/nmslib/hnswlib/tree/master#supported-distances\n",
    "  * https://github.com/hwchase17/langchain/blob/master/langchain/vectorstores/chroma.py\n",
    "  * https://github.com/hwchase17/langchain/blob/master/langchain/vectorstores/utils.py#L10\n",
    "\n",
    "For a look at some of the top performing closed and open source text embedding models, check out the HuggingFace Massive Text Embedding Benchmark (MTEB), \n",
    "* https://huggingface.co/spaces/mteb/leaderboard\n",
    "  \n",
    "For a more detailed introduction to embeddings in general, see the embeddings notebook\n",
    "* https://github.com/FMurray/hyperdemocracy/blob/main/sidequests/embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdBDoTvLbLfZ"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROVIDER == \"HF\":\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=CONFIG[\"embd\"])\n",
    "elif PROVIDER == \"OPENAI\":\n",
    "    embeddings = OpenAIEmbeddings(model=CONFIG[\"embd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DOCS=len(docs)\n",
    "persist_directory = f\"hyperdemocracy-chromadb-prov-{PROVIDER}-ndocs-{NUM_DOCS}\"\n",
    "print(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18-prZMJFisk"
   },
   "outputs": [],
   "source": [
    "## THIS CELL SPENDS MONEY THE FIRST TIME ##\n",
    "if os.path.exists(persist_directory):\n",
    "    vec_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "else:\n",
    "    batch_size = 128\n",
    "    for ii in tqdm(range(0, len(split_docs), batch_size)):\n",
    "        batch = split_docs[ii:ii+batch_size]\n",
    "        if ii == 0:\n",
    "            vec_store = Chroma.from_documents(batch, embeddings, persist_directory=persist_directory)\n",
    "        else:\n",
    "            vec_store.add_documents(batch)\n",
    "        time.sleep(1.0)\n",
    "    vec_store.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8wCr8FuFnUf"
   },
   "outputs": [],
   "source": [
    "vec_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl4Zh4V5FqEM"
   },
   "outputs": [],
   "source": [
    "ret_docs = vec_store.similarity_search_with_score(\n",
    "    \"nuclear power\", \n",
    "    k=3, \n",
    "    filter={\"source\": \"https://www.congress.gov/bill/118th-congress/house-concurrent-resolution/17\"},\n",
    ")\n",
    "\n",
    "print(\"number of returned docs: \", len(ret_docs))\n",
    "for doc in ret_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Bdr41mxrb-rn"
   },
   "source": [
    "# Part 3 - Build A RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bllOTmFfWdS"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# base classes to examine\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from langchain.schema import BaseRetriever"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Retriever from Chroma VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBt_jRxmF94T"
   },
   "outputs": [],
   "source": [
    "retriever = vec_store.as_retriever(search_kwargs={'k':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODHd9ltGQlq"
   },
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an LLM\n",
    "\n",
    "With LangChain we can use a text completion model or a chat model for QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROVIDER == \"HF\":\n",
    "    # https://huggingface.co/docs/api-inference/detailed_parameters#text-generation-task\n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=CONFIG[\"llm\"],\n",
    "        model_kwargs={\n",
    "            \"temperature\": 0,\n",
    "            \"max_length\": 128,\n",
    "            \"top_p\": 0.95,\n",
    "            \"repetition_penalty\": 5.0,\n",
    "        })\n",
    "elif PROVIDER == \"OPENAI\":\n",
    "    if CONFIG[\"llm\"].startswith(\"text\"):\n",
    "        llm = OpenAI(model_name=CONFIG[\"llm\"], temperature=0)\n",
    "    elif CONFIG[\"llm\"].startswith(\"gpt\"):\n",
    "        llm = ChatOpenAI(model_name=CONFIG[\"llm\"], temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPEKaYi3GmE1"
   },
   "outputs": [],
   "source": [
    "# create a RetrievalQA Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XukLCIikWVp"
   },
   "outputs": [],
   "source": [
    "## THIS CELL SPENDS MONEY ##\n",
    "query = \"What are the primary themes around energy policy?\"\n",
    "with get_openai_callback() as cb:\n",
    "    out = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in out['source_documents']:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = qa(\"What is the solution to climate change?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in out['source_documents']:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity\n",
    "\n",
    "* what are the components of the RetrievalQA chain?\n",
    "* what is the QA prompt?\n",
    "* how would you modify the QA prompt?\n",
    "* what is the difference between the following qa chain types?,\n",
    "    * stuff\n",
    "    * map_reduce\n",
    "    * map_rerank\n",
    "    * refine\n",
    " \n",
    "## Resources\n",
    "\n",
    "* https://python.langchain.com/docs/modules/chains/document/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseCombineDocumentsChain?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombineDocumentChains\n",
    "\n",
    "* https://python.langchain.com/docs/modules/chains/document/stuff\n",
    "* https://python.langchain.com/docs/modules/chains/document/refine\n",
    "* https://python.langchain.com/docs/modules/chains/document/map_reduce\n",
    "* https://python.langchain.com/docs/modules/chains/document/map_rerank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8MdA3SOznZkm"
   },
   "source": [
    "## Examine the RetrievalQA Prompt \n",
    "\n",
    "Note that the prompt template used will depend on the choice of LLM (text completion vs chat). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhmxZhEIbbpR"
   },
   "outputs": [],
   "source": [
    "prompt_template = qa.combine_documents_chain.llm_chain.prompt\n",
    "print(prompt_template)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cR-f8EBgjwOi"
   },
   "source": [
    "# Part 4 - Create a RetrievalQAWithSourcesChain\n",
    "\n",
    "Now we will do the same thing using a chain that provides sources in the generated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GDnvwb2jzxy"
   },
   "outputs": [],
   "source": [
    "qaws = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwOMdmEmj5qE"
   },
   "outputs": [],
   "source": [
    "## THIS CELL SPENDS MONEY ##\n",
    "out = qaws(\"What is the solution to climate change?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGtEw6NVj_nj"
   },
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flHelL8nkLEy"
   },
   "outputs": [],
   "source": [
    "print(out['source_documents'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity \n",
    "\n",
    "* In this example, all of the returned document chunks came from one original document (118HCONRES37). What can be done to encourage a more diverse set of documents?\n",
    "* What prompt is used? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIBbG6f6BFC5"
   },
   "outputs": [],
   "source": [
    "pt = qaws.combine_documents_chain.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B90CgFIDBDmM"
   },
   "outputs": [],
   "source": [
    "print(pt.format(summaries='[SUMMARIES]', question='[QUESTION]'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "qxLyw-PlJIMQ"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool, DuckDuckGoSearchRun\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-3.8.3-py3-none-any.whl (18 kB)\n",
      "Collecting aiofiles>=23.1.0 (from duckduckgo-search)\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in ./venv/lib/python3.10/site-packages (from duckduckgo-search) (8.1.3)\n",
      "Collecting lxml>=4.9.2 (from duckduckgo-search)\n",
      "  Using cached lxml-4.9.2.tar.gz (3.7 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx[brotli,http2,socks]>=0.24.1 (from duckduckgo-search)\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (2023.5.7)\n",
      "Collecting httpcore<0.18.0,>=0.15.0 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in ./venv/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (3.4)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (1.3.0)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting socksio==1.* (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-macosx_10_9_universal2.whl (786 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.7/786.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./venv/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (3.7.0)\n",
      "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (1.1.1)\n",
      "Building wheels for collected packages: lxml\n",
      "  Building wheel for lxml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-4.9.2-cp310-cp310-macosx_11_0_arm64.whl size=1590450 sha256=cfa2b1275bfe9ba01958c49212a726eb12a0a0cff1a9e65cbce95c78e0a92207\n",
      "  Stored in directory: /Users/forrestmurray/Library/Caches/pip/wheels/5a/51/0e/95b4a6ddee4a616530c36aeb03dafb5e04183756d9973a7d5d\n",
      "Successfully built lxml\n",
      "Installing collected packages: brotli, socksio, lxml, hyperframe, hpack, aiofiles, httpcore, h2, httpx, duckduckgo-search\n",
      "Successfully installed aiofiles-23.1.0 brotli-1.0.9 duckduckgo-search-3.8.3 h2-4.1.0 hpack-4.0.0 httpcore-0.17.2 httpx-0.24.1 hyperframe-6.0.1 lxml-4.9.2 socksio-1.0.0\n"
     ]
    }
   ],
   "source": [
    "%pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # create a tool that has a name, description and function\n",
    "    Tool(\n",
    "        name=\"Assemble Co QA System\",\n",
    "        func=qa.run,\n",
    "        description=\"Always use this when answering questions about legislation.\",\n",
    "    ),\n",
    "    # Can use prebuilt tools too\n",
    "    DuckDuckGoSearchRun(), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Assemble Co QA System to answer the first part of the question, as it is about legislation. For the second part, I might need to use duckduckgo_search to find information on quantifying the impact of climate change proposals.\n",
      "Action: Assemble Co QA System\n",
      "Action Input: What is congress proposing to do about climate change?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mCongress is proposing to create a Green New Deal, which aims to address climate change by achieving greenhouse gas and toxic emissions reductions, creating millions of high-wage union jobs, investing in infrastructure and industry, and promoting clean energy. The Green New Deal also emphasizes the importance of protecting vulnerable communities and restoring natural ecosystems. Additionally, Congress is committed to embracing nuclear power as a clean baseload energy source to achieve energy independence and reduce carbon emissions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now need to find information on quantifying the impact of climate change proposals.\n",
      "Action: duckduckgo_search\n",
      "Action Input: How to quantify the impact of climate change proposals?\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/forrestmurray/Projects/hyperdemocracy/venv/lib/python3.10/site-packages/duckduckgo_search/compat.py:20: UserWarning: ddg is deprecated. Use DDGS().text() generator\n",
      "  warnings.warn(\"ddg is deprecated. Use DDGS().text() generator\")\n",
      "/Users/forrestmurray/Projects/hyperdemocracy/venv/lib/python3.10/site-packages/duckduckgo_search/compat.py:22: UserWarning: parameter time is deprecated, use parameter timelimit\n",
      "  warnings.warn(\"parameter time is deprecated, use parameter timelimit\")\n",
      "/Users/forrestmurray/Projects/hyperdemocracy/venv/lib/python3.10/site-packages/duckduckgo_search/compat.py:24: UserWarning: parameter page is deprecated, use DDGS().text() generator\n",
      "  warnings.warn(\"parameter page is deprecated, use DDGS().text() generator\")\n",
      "/Users/forrestmurray/Projects/hyperdemocracy/venv/lib/python3.10/site-packages/duckduckgo_search/compat.py:26: UserWarning: parameter max_results is deprecated, use DDGS().text()\n",
      "  warnings.warn(\"parameter max_results is deprecated, use DDGS().text()\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mClimate policy curves quantify the relationship between a carbon price and future increases in global temperatures. They incorporate two important relationships: the economic link from carbon... A rapidly increasing literature base is quantifying associations between climate change and health outcomes. Here Ebi reviews methods for quantifying, projecting, and managing the health risks of... Climate risks could affect the Budget and the overall fiscal outlook through a number of pathways, including altering total tax revenue through effects on Gross Domestic Product (GDP) growth, and... The proposal development stage is also an appropriate time to plan how impacts of climate change and other stressors on project area resources will be analyzed. Becoming familiar with the current and projected climate change impacts on the project area will help in identification of which resources are most likely to be affected. Using detailed models of sectoral impacts (e.g., human health, infrastructure, and water resources), the project seeks to quantify and monetize how risks, impacts, and damages may change in response to greenhouse gas mitigation and adaptation actions. 2023 Climate and Children's Health Report\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: Congress is proposing to create a Green New Deal to address climate change, which includes measures such as reducing greenhouse gas emissions, creating jobs, investing in infrastructure and clean energy, and protecting vulnerable communities. To quantify the impact of climate change proposals, various methods can be used, such as climate policy curves, analyzing health outcomes, assessing fiscal impacts, and using detailed models to quantify and monetize risks, impacts, and damages.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Congress is proposing to create a Green New Deal to address climate change, which includes measures such as reducing greenhouse gas emissions, creating jobs, investing in infrastructure and clean energy, and protecting vulnerable communities. To quantify the impact of climate change proposals, various methods can be used, such as climate policy curves, analyzing health outcomes, assessing fiscal impacts, and using detailed models to quantify and monetize risks, impacts, and damages.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What is congress proposing to do about climate change? How could we quantify the impact of their proposals?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Assemble Co QA System to answer this question about legislation.\n",
      "Action: Assemble Co QA System\n",
      "Action Input: What financial incentives might the sponsors of the related legislation stand to gain from their proposals?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mBased on the provided context, the sponsors of the related legislation might stand to gain financial assistance or incentives. These incentives could include covered incentives offered by governmental entities, financial assistance previously provided under this subsection, and potential benefits from the covered entity receiving financial assistance. However, the specific details of these financial incentives are not mentioned in the given context.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The sponsors of the related legislation might stand to gain financial assistance or incentives, but the specific details are not mentioned in the given context.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sponsors of the related legislation might stand to gain financial assistance or incentives, but the specific details are not mentioned in the given context.'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"What financial incentives might the sponsors of the related legislation stand to gain from their proposals?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Assemble Co QA System to find the sponsors of the legislation.\n",
      "Action: Assemble Co QA System\n",
      "Action Input: Who are the sponsors of the related legislation?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe sponsors of the related legislation are Ms. Velazquez, Ms. Tlaib, Mr. Tonko, Ms. Lee of California, Ms. Stansbury, Mr. Gallego, Mrs. McBath, Mr. Cleaver, Ms. McCollum, Mr. Meeks, Mr. Payne, Ms. Ocasio-Cortez, Mr. Moskowitz, Mr. Kim of New Jersey, and Mr. DeSaulnier for the first bill, and Griffith, Mrs. Lesko, Mr. Mike Garcia of California, Mr. Langworthy, Ms. Stefanik, Ms. Van Duyne, Mrs. Spartz, Ms. Tenney, Mr. Webster of Florida, Mr. Weber of Texas, Mr. Issa, Mr. Balderson, Ms. Malliotakis, Mr. Stauber, Mr. Zinke, Mr. Smith of Missouri, Ms. Mace, Mrs. Kiggans of Virginia, Mr. Fallon, and Mr. Valadao for the second bill.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The sponsors of the related legislation are Ms. Velazquez, Ms. Tlaib, Mr. Tonko, Ms. Lee of California, Ms. Stansbury, Mr. Gallego, Mrs. McBath, Mr. Cleaver, Ms. McCollum, Mr. Meeks, Mr. Payne, Ms. Ocasio-Cortez, Mr. Moskowitz, Mr. Kim of New Jersey, and Mr. DeSaulnier for the first bill, and Griffith, Mrs. Lesko, Mr. Mike Garcia of California, Mr. Langworthy, Ms. Stefanik, Ms. Van Duyne, Mrs. Spartz, Ms. Tenney, Mr. Webster of Florida, Mr. Weber of Texas, Mr. Issa, Mr. Balderson, Ms. Malliotakis, Mr. Stauber, Mr. Zinke, Mr. Smith of Missouri, Ms. Mace, Mrs. Kiggans of Virginia, Mr. Fallon, and Mr. Valadao for the second bill.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sponsors of the related legislation are Ms. Velazquez, Ms. Tlaib, Mr. Tonko, Ms. Lee of California, Ms. Stansbury, Mr. Gallego, Mrs. McBath, Mr. Cleaver, Ms. McCollum, Mr. Meeks, Mr. Payne, Ms. Ocasio-Cortez, Mr. Moskowitz, Mr. Kim of New Jersey, and Mr. DeSaulnier for the first bill, and Griffith, Mrs. Lesko, Mr. Mike Garcia of California, Mr. Langworthy, Ms. Stefanik, Ms. Van Duyne, Mrs. Spartz, Ms. Tenney, Mr. Webster of Florida, Mr. Weber of Texas, Mr. Issa, Mr. Balderson, Ms. Malliotakis, Mr. Stauber, Mr. Zinke, Mr. Smith of Missouri, Ms. Mace, Mrs. Kiggans of Virginia, Mr. Fallon, and Mr. Valadao for the second bill.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Who are the sponsors of the related legislation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationBufferMemory</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_memory</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatMessageHistory</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'what is the solution to climate change?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'N/A'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'what is the solution to climate change?'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The solution to climate change involves a multi-faceted approach, including shifting to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">renewable energy sources, implementing sustainable agriculture practices, improving transportation systems, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implementing nature-based solutions.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is congress doing about climate change?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Congress is taking various actions to address climate change, including passing the Clean </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Energy and Climate Investments Bill, making amendments to the Clean Air Act, and approving the Inflation Reduction </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Act of 2022, which delivers the largest investment in climate action in U.S. history.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is congress doing about climate change?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Congress is taking action on climate change through various resolutions and legislation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as the Green New Deal resolution and a resolution recognizing the urgency of addressing climate change and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embracing nuclear power as a clean energy source.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What is congress proposing to do about climate change? How could we quantify the impact of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their proposals?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Congress is proposing to create a Green New Deal to address climate change, which includes</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">measures such as reducing greenhouse gas emissions, creating jobs, investing in infrastructure and clean energy, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and protecting vulnerable communities. To quantify the impact of climate change proposals, various methods can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used, such as climate policy curves, analyzing health outcomes, assessing fiscal impacts, and using detailed models</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to quantify and monetize risks, impacts, and damages.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What financial incentives might the sponsors of the related legislation stand to gain from</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their proposals?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The sponsors of the related legislation might stand to gain financial assistance or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">incentives, but the specific details are not mentioned in the given context.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Who are the sponsors of the related legislation?'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The sponsors of the related legislation are Ms. Velazquez, Ms. Tlaib, Mr. Tonko, Ms. Lee </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of California, Ms. Stansbury, Mr. Gallego, Mrs. McBath, Mr. Cleaver, Ms. McCollum, Mr. Meeks, Mr. Payne, Ms. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Ocasio-Cortez, Mr. Moskowitz, Mr. Kim of New Jersey, and Mr. DeSaulnier for the first bill, and Griffith, Mrs. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lesko, Mr. Mike Garcia of California, Mr. Langworthy, Ms. Stefanik, Ms. Van Duyne, Mrs. Spartz, Ms. Tenney, Mr. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Webster of Florida, Mr. Weber of Texas, Mr. Issa, Mr. Balderson, Ms. Malliotakis, Mr. Stauber, Mr. Zinke, Mr. Smith</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Missouri, Ms. Mace, Mrs. Kiggans of Virginia, Mr. Fallon, and Mr. Valadao for the second bill.'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">example</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">output_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">return_messages</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">human_prefix</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Human'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">ai_prefix</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">memory_key</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat_history'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mConversationBufferMemory\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mchat_memory\u001b[0m=\u001b[1;35mChatMessageHistory\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'what is the solution to climate change?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'N/A'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'what is the solution to climate change?'\u001b[0m, \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The solution to climate change involves a multi-faceted approach, including shifting to \u001b[0m\n",
       "\u001b[32mrenewable energy sources, implementing sustainable agriculture practices, improving transportation systems, and \u001b[0m\n",
       "\u001b[32mimplementing nature-based solutions.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'What is congress doing about climate change?'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Congress is taking various actions to address climate change, including passing the Clean \u001b[0m\n",
       "\u001b[32mEnergy and Climate Investments Bill, making amendments to the Clean Air Act, and approving the Inflation Reduction \u001b[0m\n",
       "\u001b[32mAct of 2022, which delivers the largest investment in climate action in U.S. history.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'What is congress doing about climate change?'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Congress is taking action on climate change through various resolutions and legislation, \u001b[0m\n",
       "\u001b[32msuch as the Green New Deal resolution and a resolution recognizing the urgency of addressing climate change and \u001b[0m\n",
       "\u001b[32membracing nuclear power as a clean energy source.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'What is congress proposing to do about climate change? How could we quantify the impact of\u001b[0m\n",
       "\u001b[32mtheir proposals?'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Congress is proposing to create a Green New Deal to address climate change, which includes\u001b[0m\n",
       "\u001b[32mmeasures such as reducing greenhouse gas emissions, creating jobs, investing in infrastructure and clean energy, \u001b[0m\n",
       "\u001b[32mand protecting vulnerable communities. To quantify the impact of climate change proposals, various methods can be \u001b[0m\n",
       "\u001b[32mused, such as climate policy curves, analyzing health outcomes, assessing fiscal impacts, and using detailed models\u001b[0m\n",
       "\u001b[32mto quantify and monetize risks, impacts, and damages.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'What financial incentives might the sponsors of the related legislation stand to gain from\u001b[0m\n",
       "\u001b[32mtheir proposals?'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The sponsors of the related legislation might stand to gain financial assistance or \u001b[0m\n",
       "\u001b[32mincentives, but the specific details are not mentioned in the given context.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'Who are the sponsors of the related legislation?'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The sponsors of the related legislation are Ms. Velazquez, Ms. Tlaib, Mr. Tonko, Ms. Lee \u001b[0m\n",
       "\u001b[32mof California, Ms. Stansbury, Mr. Gallego, Mrs. McBath, Mr. Cleaver, Ms. McCollum, Mr. Meeks, Mr. Payne, Ms. \u001b[0m\n",
       "\u001b[32mOcasio-Cortez, Mr. Moskowitz, Mr. Kim of New Jersey, and Mr. DeSaulnier for the first bill, and Griffith, Mrs. \u001b[0m\n",
       "\u001b[32mLesko, Mr. Mike Garcia of California, Mr. Langworthy, Ms. Stefanik, Ms. Van Duyne, Mrs. Spartz, Ms. Tenney, Mr. \u001b[0m\n",
       "\u001b[32mWebster of Florida, Mr. Weber of Texas, Mr. Issa, Mr. Balderson, Ms. Malliotakis, Mr. Stauber, Mr. Zinke, Mr. Smith\u001b[0m\n",
       "\u001b[32mof Missouri, Ms. Mace, Mrs. Kiggans of Virginia, Mr. Fallon, and Mr. Valadao for the second bill.'\u001b[0m,\n",
       "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[33mexample\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33moutput_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33minput_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mreturn_messages\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mhuman_prefix\u001b[0m=\u001b[32m'Human'\u001b[0m,\n",
       "    \u001b[33mai_prefix\u001b[0m=\u001b[32m'AI'\u001b[0m,\n",
       "    \u001b[33mmemory_key\u001b[0m=\u001b[32m'chat_history'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
